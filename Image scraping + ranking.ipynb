{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get response:\n",
    " => Not as robust as it should be\n",
    " => If not working, try change the my_headers[] used in the 24th line to a different header\n",
    "     \n",
    "'''\n",
    "def get_response(url):\n",
    "    my_headers = [\n",
    "     'Mozilla/5.0',\n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14\",\n",
    "    \"Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)\",\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11',\n",
    "    'Opera/9.25 (Windows NT 5.1; U; en)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)',\n",
    "    'Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)',\n",
    "    'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12',\n",
    "    'Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9',\n",
    "    \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7\",     \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0 \"\n",
    "]\n",
    "    req = request.Request(url)\n",
    "#     req.add_header('User-Agent', random.choice(my_headers))\n",
    "    req.add_header('User-Agent',my_headers[3])\n",
    "    response = urlopen(req)\n",
    "    page = response.read()\n",
    "#     if response.getcode()==200:\n",
    "#         page = response.read()\n",
    "#     else:\n",
    "#         raise Exception('Can\\'t get page ')\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get images on a specific image address:\n",
    " => Need to change file directory as needed\n",
    "'''\n",
    "def get_images(url):\n",
    "        # Open the url image, set stream to True, this will return the stream content.\n",
    "        resp = requests.get(url, stream=True)\n",
    "        # Open a local file with wb ( write binary ) permission.\n",
    "        local_file = open('./images/local_image.jpg', 'wb')\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        resp.raw.decode_content = True\n",
    "        # Copy the response stream raw data to local image file.\n",
    "        shutil.copyfileobj(resp.raw, local_file)\n",
    "        # Remove the image url response object.\n",
    "        del resp\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with page No. 1/ Total 4 pages\n",
      "Finished with page No. 2/ Total 4 pages\n",
      "Finished with page No. 3/ Total 4 pages\n",
      "Finished with page No. 4/ Total 4 pages\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get school ranking, this will download the Top 100 schools, 25 schools per page, 4 pages in total\n",
    "'''\n",
    "\n",
    "dict = {}\n",
    "ranking=1\n",
    "for pages in range(1,5):\n",
    "    if pages== 1:\n",
    "        html ='https://www.niche.com/k12/search/best-private-high-schools/'\n",
    "    else:\n",
    "        html ='https://www.niche.com/k12/search/best-private-high-schools/?page='+ str(pages) \n",
    "    page=get_response(html)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(page) \n",
    "    schools = soup.find_all(match_class([\"search-result__title\"]))\n",
    "    for school in schools:\n",
    "        dict[ranking] = school.get_text()\n",
    "        ranking+=1\n",
    "    print(\"Finished with page No. \"+ str(pages) +\"/ Total 4 pages\")\n",
    "school_ranking = pd.DataFrame.from_dict(dict, orient='index')\n",
    "school_ranking.to_csv(\"School Ranking\",header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Web-scrapping a whole webpage, for example a wiki page, not necessarily used in this project\n",
    "'''\n",
    "def filter_img(soup):\n",
    "    links = soup.findAll('img')\n",
    "    if len(links)==0:\n",
    "        raise Exception('No matched tag')\n",
    "    else:\n",
    "        return links\n",
    "    \n",
    "def get_pictures(url):\n",
    "    page = get_response(url)\n",
    "    soup = BeautifulSoup(page)\n",
    "    links = filter_img(soup)\n",
    "    img_urls={}\n",
    "    for i in range(0,len(links)):\n",
    "        if links[i].get('src').startswith('http'):\n",
    "            img_urls[i] = links[i].get('src')\n",
    "    src = pd.DataFrame.from_dict(img_urls,orient='index',columns=['urls']).drop_duplicates()\n",
    "    src.to_csv(\"testdf\")\n",
    "    for index in range(1,src.size):\n",
    "        img_url=src.iloc[index]['urls']\n",
    "        # Open the url image, set stream to True, this will return the stream content.\n",
    "        resp = requests.get(img_url, stream=True)\n",
    "        # Open a local file with wb ( write binary ) permission.\n",
    "        local_file = open('./images/local_image'+str(index)+'.jpg', 'wb')\n",
    "        # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "        resp.raw.decode_content = True\n",
    "        # Copy the response stream raw data to local image file.\n",
    "        shutil.copyfileobj(resp.raw, local_file)\n",
    "        # Remove the image url response object.\n",
    "        del resp\n",
    "    return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
